# ğŸš€ åŸºæ–¼è¼•é‡ CUDA 12.1 Runtimeï¼ˆå®˜æ–¹ PyTorch with Python 3.10ï¼‰
FROM pytorch/pytorch:2.1.0-cuda12.1-cudnn8-runtime

# âœ… åŸºæœ¬è¨­å®š
ENV DEBIAN_FRONTEND=noninteractive
ENV TZ=Etc/UTC
ENV PYTHONUNBUFFERED=1

# ğŸ§© å®‰è£å¿…è¦å¥—ä»¶ï¼ˆåŒ…å« ffmpegã€curlï¼‰
RUN apt-get update && apt-get install -y \
    git \
    ffmpeg \
    curl \
    libsm6 \
    libxext6 \
    tzdata \
 && rm -rf /var/lib/apt/lists/*

# âš™ï¸ è¨­å®šå·¥ä½œç›®éŒ„
WORKDIR /workspace
COPY . /workspace

# ğŸ å®‰è£ PyTorch GPU å°æ‡‰ç‰ˆæœ¬
RUN pip install --no-cache-dir --upgrade pip && \
    pip install --no-cache-dir torch==2.1.0 torchvision==0.16.0 --index-url https://download.pytorch.org/whl/cu121

# ğŸ“¦ å®‰è£ä¾è³´ï¼ˆrequirements.txt + runpodï¼‰
RUN pip install --no-cache-dir -r requirements.txt && \
    pip install --no-cache-dir runpod requests

# ğŸŒ RunPod Serverless é è¨­ä½¿ç”¨ port 5000
EXPOSE 5000

# ğŸš¦ å¥åº·æª¢æŸ¥
HEALTHCHECK --interval=30s --timeout=5s --retries=3 \
 CMD curl -f http://localhost:5000/ || exit 1

# â–¶ï¸ å•Ÿå‹• RunPod Serverless handler
CMD ["python", "server.py"]
